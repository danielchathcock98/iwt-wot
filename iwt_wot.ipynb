{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iwt-wot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roK0Qml8d0-3",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Setup cells for running if Google Colab. Ignore if running locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQGsOGC0tt2w",
        "colab_type": "code",
        "outputId": "1a80ca22-7621-4f0c-bf6c-e648fc491d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2385855 sha256=1580e57e61fa6bb4e694e56c05d4659b8f90d8155eeaa2f05b83932abc94c760\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Tmq7-BJkNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNp-0fHU9g1a",
        "colab_type": "code",
        "outputId": "660047a1-b0d8-4765-a1c1-03282f990e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYaKi4PnBIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, 'drive/My Drive/iwt-wot/')\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XlATNWFd94N",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Loading Pre-trained Word Embeddings\n",
        "\n",
        "Make sure to change DRIVE_DIR in cell below based on the location of the iwt-wot folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s7FZVrAswbr",
        "colab_type": "code",
        "outputId": "f5b1afa5-fdef-482c-f98e-5e232b89ac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from wordEmbedding import Embedding\n",
        "\n",
        "import random\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "random.seed(1)\n",
        "print(device)\n",
        "\n",
        "DRIVE_DIR = Path('drive/My Drive/iwt-wot/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkzwP6h57ob9",
        "colab_type": "code",
        "outputId": "b5829e92-3da4-4a9d-df41-db8df7dd5412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('about to load embeddings')\n",
        "embed = Embedding(DRIVE_DIR)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load embeddings\n",
            "loading embedding model\n",
            "loaded embedding model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfPe9pcyeLi1",
        "colab_type": "text"
      },
      "source": [
        "# Sub-task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eImMzoYeNWI",
        "colab_type": "text"
      },
      "source": [
        "## Model 2\n",
        "\n",
        "Training of model 2 for sub-task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4IKIhEfolEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import Model25 as Model2\n",
        "from preprocessing import model2preprocessing, TASK_1, EXTRA_TRAIN_TASK_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmpXeIh17k7e",
        "colab_type": "code",
        "outputId": "14c24f36-afaa-4e91-caee-cee0ccbb2a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model2preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1])\n",
        "print('loaded training data')\n",
        "val_data = model2preprocessing([DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded val data')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded val data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9xQQB5R879q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for inputData, score in training_data:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding)\n",
        "\n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "    avg_val_loss, val_rmse = evaluate(model, loss_function, optimizer)\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tAvg Val Loss: {:.4f}\\t Train RMSE: {:.4f}\\t Val RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      avg_val_loss,\n",
        "                                                                      train_rmse,\n",
        "                                                                      val_rmse))\n",
        "    \n",
        "    return train_rmse, val_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsHNX46S9FHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, loss_function, optimizer):\n",
        "  # returns:: avg_val_loss (float)\n",
        "  # returns:: val_accuracy (float)\n",
        "    val_loss = 0\n",
        "    square_error = 0\n",
        "    val_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputData, score in val_data:\n",
        "            embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        "            score_output = model(embedding)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            val_loss += loss.item()\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            val_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / val_examples)\n",
        "    avg_val_loss = val_loss / val_examples\n",
        "    return avg_val_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRDmnyNJsy9N",
        "colab_type": "code",
        "outputId": "fbe9b4c9-069c-4621-e3f6-ec48f21a2b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "HIDDEN_DIM = 6\n",
        "LEARNING_RATE = 0.2\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 30\n",
        "\n",
        "print(device)\n",
        "model2 = Model2(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "t_rmses = []\n",
        "v_rmses = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr, vr = train(epoch, model2, loss_function, optimizer)\n",
        "    t_rmses.append(tr)\n",
        "    v_rmses.append(vr)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/30\tAvg Train Loss: 0.3870\tAvg Val Loss: 0.3685\t Train RMSE: 0.6221\t Val RMSE: 0.6070\n",
            "Epoch: 2/30\tAvg Train Loss: 0.3800\tAvg Val Loss: 0.3576\t Train RMSE: 0.6164\t Val RMSE: 0.5980\n",
            "Epoch: 3/30\tAvg Train Loss: 0.3690\tAvg Val Loss: 0.3549\t Train RMSE: 0.6074\t Val RMSE: 0.5957\n",
            "Epoch: 4/30\tAvg Train Loss: 0.3581\tAvg Val Loss: 0.3470\t Train RMSE: 0.5984\t Val RMSE: 0.5891\n",
            "Epoch: 5/30\tAvg Train Loss: 0.3498\tAvg Val Loss: 0.3429\t Train RMSE: 0.5914\t Val RMSE: 0.5856\n",
            "Epoch: 6/30\tAvg Train Loss: 0.3424\tAvg Val Loss: 0.3409\t Train RMSE: 0.5852\t Val RMSE: 0.5839\n",
            "Epoch: 7/30\tAvg Train Loss: 0.3364\tAvg Val Loss: 0.3420\t Train RMSE: 0.5800\t Val RMSE: 0.5848\n",
            "Epoch: 8/30\tAvg Train Loss: 0.3309\tAvg Val Loss: 0.3427\t Train RMSE: 0.5752\t Val RMSE: 0.5854\n",
            "Epoch: 9/30\tAvg Train Loss: 0.3259\tAvg Val Loss: 0.3413\t Train RMSE: 0.5709\t Val RMSE: 0.5842\n",
            "Epoch: 10/30\tAvg Train Loss: 0.3212\tAvg Val Loss: 0.3400\t Train RMSE: 0.5667\t Val RMSE: 0.5831\n",
            "Epoch: 11/30\tAvg Train Loss: 0.3170\tAvg Val Loss: 0.3387\t Train RMSE: 0.5631\t Val RMSE: 0.5820\n",
            "Epoch: 12/30\tAvg Train Loss: 0.3133\tAvg Val Loss: 0.3368\t Train RMSE: 0.5597\t Val RMSE: 0.5804\n",
            "Epoch: 13/30\tAvg Train Loss: 0.3088\tAvg Val Loss: 0.3357\t Train RMSE: 0.5557\t Val RMSE: 0.5794\n",
            "Epoch: 14/30\tAvg Train Loss: 0.3054\tAvg Val Loss: 0.3363\t Train RMSE: 0.5526\t Val RMSE: 0.5799\n",
            "Epoch: 15/30\tAvg Train Loss: 0.3023\tAvg Val Loss: 0.3412\t Train RMSE: 0.5498\t Val RMSE: 0.5841\n",
            "Epoch: 16/30\tAvg Train Loss: 0.2987\tAvg Val Loss: 0.3449\t Train RMSE: 0.5465\t Val RMSE: 0.5873\n",
            "Epoch: 17/30\tAvg Train Loss: 0.2963\tAvg Val Loss: 0.3567\t Train RMSE: 0.5443\t Val RMSE: 0.5973\n",
            "Epoch: 18/30\tAvg Train Loss: 0.2931\tAvg Val Loss: 0.3601\t Train RMSE: 0.5414\t Val RMSE: 0.6001\n",
            "Epoch: 19/30\tAvg Train Loss: 0.2915\tAvg Val Loss: 0.3647\t Train RMSE: 0.5400\t Val RMSE: 0.6039\n",
            "Epoch: 20/30\tAvg Train Loss: 0.3084\tAvg Val Loss: 0.3600\t Train RMSE: 0.5553\t Val RMSE: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-162eed2f3ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mt_rmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mv_rmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f8b9b7c4d18d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# score_tensor = torch.tensor([1 - score_prob, score_prob]).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mscore_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/iwt-wot/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoded_sentence)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_hn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_hn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprobability_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNe8lAYK_P5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c1648737-9f7b-4470-edee-c1ad25ebd50f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(range(len(t_rmses)), t_rmses, 'r', label='train')\n",
        "plt.plot(range(len(v_rmses)), v_rmses, 'g', label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(np.arange(1, 21, 2)-1, np.arange(1, 21, 2))\n",
        "\n",
        "plt.savefig('overfitting.png')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9fJJkYreWYN",
        "colab_type": "text"
      },
      "source": [
        "## Model 1\n",
        "\n",
        "Training of model 1 for sub-task 1 (also for sub-task 2, since we simply create a model for sub-task 2 directly from Model 1 for sub-task 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8xa3ixJko8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import Model25 as Model1\n",
        "from preprocessing import model1preprocessing, TASK_1, EXTRA_TRAIN_TASK_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6dyDs1PwkcE",
        "colab_type": "code",
        "outputId": "afec19a8-db8a-4fa1-cc73-a85e21e03db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model1preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1])\n",
        "print('loaded training data')\n",
        "val_data = model1preprocessing([DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded val data')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded val data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BwpEFY9xG6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for inputData, score in training_data[1::2]:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding)\n",
        "        \n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "    avg_val_loss, val_rmse = evaluate(model, loss_function, optimizer)\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tAvg Val Loss: {:.4f}\\t Train RMSE: {:.4f}\\t Val RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      avg_val_loss,\n",
        "                                                                      train_rmse,\n",
        "                                                                      val_rmse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqTQpDXxMgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, loss_function, optimizer):\n",
        "  # returns:: avg_val_loss (float)\n",
        "  # returns:: val_accuracy (float)\n",
        "    val_loss = 0\n",
        "    square_error = 0\n",
        "    val_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputData, score in val_data[1::2]:\n",
        "            embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "            score_output = model(embedding)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            val_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / val_examples)\n",
        "    avg_val_loss = val_loss / val_examples\n",
        "    return avg_val_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjffpJtJxM9l",
        "colab_type": "code",
        "outputId": "e3819fda-db8d-4be6-c198-5dcba589cee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "HIDDEN_DIM = 6\n",
        "LEARNING_RATE = 0.18\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 30\n",
        "\n",
        "print(device)\n",
        "model1 = Model1(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, model1, loss_function, optimizer)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/30\tAvg Train Loss: 0.3783\tAvg Val Loss: 0.3814\t Train RMSE: 0.6151\t Val RMSE: 0.6176\n",
            "Epoch: 2/30\tAvg Train Loss: 0.3690\tAvg Val Loss: 0.3673\t Train RMSE: 0.6074\t Val RMSE: 0.6060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-96f1a28ba816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-8f75a00671e3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mscore_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mscore_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/iwt-wot/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoded_sentence)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_hn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_hn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprobability_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    547\u001b[0m             zeros = torch.zeros(self.num_layers * num_directions,\n\u001b[1;32m    548\u001b[0m                                 \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                                 dtype=input.dtype, device=input.device)\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e68fVoOFxbsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVynVvpMemBx",
        "colab_type": "text"
      },
      "source": [
        "## Model 3\n",
        "\n",
        "Training for model 3 for sub-task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_LH3zad2BzJ",
        "colab": {}
      },
      "source": [
        "from model import Model3\n",
        "from preprocessing import model3preprocessing, TASK_1, EXTRA_TRAIN_TASK_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0dab1750-4541-4372-acc7-7ba3a62ade2c",
        "id": "ROHOGbyM2H-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model3preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1])\n",
        "print('loaded training data')\n",
        "val_data = model3preprocessing([DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded val data')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded val data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMa-FxQa2H_B",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for originalSent, newSent, score in training_data:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding1 = torch.tensor(embed.embed_sentence(originalSent)).to(device)\n",
        "        embedding2 = torch.tensor(embed.embed_sentence(newSent)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding1, embedding2)\n",
        "        \n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "    avg_val_loss, val_rmse = evaluate(model, loss_function, optimizer)\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tAvg Val Loss: {:.4f}\\t Train RMSE: {:.4f}\\t Val RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      avg_val_loss,\n",
        "                                                                      train_rmse,\n",
        "                                                                      val_rmse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pIKioVF82H_G",
        "colab": {}
      },
      "source": [
        "def evaluate(model, loss_function, optimizer):\n",
        "  # returns:: avg_val_loss (float)\n",
        "  # returns:: val_accuracy (float)\n",
        "    val_loss = 0\n",
        "    square_error = 0\n",
        "    val_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for originalSent, newSent, score in val_data:\n",
        "            embedding1 = torch.tensor(embed.embed_sentence(originalSent)).to(device)\n",
        "            embedding2 = torch.tensor(embed.embed_sentence(newSent)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        "            score_output = model(embedding1, embedding2)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            val_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / val_examples)\n",
        "    avg_val_loss = val_loss / val_examples\n",
        "    return avg_val_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9a001b84-1c90-4002-a35d-e351664a3751",
        "id": "H-Rh66bc2H_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "HIDDEN_DIM = 3\n",
        "LEARNING_RATE = 0.18\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 30\n",
        "\n",
        "print(device)\n",
        "model3 = Model3(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model3.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, model3, loss_function, optimizer)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/30\tAvg Train Loss: 0.3801\tAvg Val Loss: 0.3777\t Train RMSE: 0.6165\t Val RMSE: 0.6146\n",
            "Epoch: 2/30\tAvg Train Loss: 0.3755\tAvg Val Loss: 0.3696\t Train RMSE: 0.6128\t Val RMSE: 0.6080\n",
            "Epoch: 3/30\tAvg Train Loss: 0.3677\tAvg Val Loss: 0.3601\t Train RMSE: 0.6064\t Val RMSE: 0.6001\n",
            "Epoch: 4/30\tAvg Train Loss: 0.3545\tAvg Val Loss: 0.3570\t Train RMSE: 0.5954\t Val RMSE: 0.5975\n",
            "Epoch: 5/30\tAvg Train Loss: 0.3433\tAvg Val Loss: 0.3485\t Train RMSE: 0.5859\t Val RMSE: 0.5904\n",
            "Epoch: 6/30\tAvg Train Loss: 0.3337\tAvg Val Loss: 0.3416\t Train RMSE: 0.5777\t Val RMSE: 0.5844\n",
            "Epoch: 7/30\tAvg Train Loss: 0.3262\tAvg Val Loss: 0.3362\t Train RMSE: 0.5711\t Val RMSE: 0.5798\n",
            "Epoch: 8/30\tAvg Train Loss: 0.3203\tAvg Val Loss: 0.3321\t Train RMSE: 0.5660\t Val RMSE: 0.5763\n",
            "Epoch: 9/30\tAvg Train Loss: 0.3155\tAvg Val Loss: 0.3291\t Train RMSE: 0.5617\t Val RMSE: 0.5737\n",
            "Epoch: 10/30\tAvg Train Loss: 0.3115\tAvg Val Loss: 0.3271\t Train RMSE: 0.5581\t Val RMSE: 0.5719\n",
            "Epoch: 11/30\tAvg Train Loss: 0.3079\tAvg Val Loss: 0.3266\t Train RMSE: 0.5549\t Val RMSE: 0.5715\n",
            "Epoch: 12/30\tAvg Train Loss: 0.3048\tAvg Val Loss: 0.3286\t Train RMSE: 0.5521\t Val RMSE: 0.5732\n",
            "Epoch: 13/30\tAvg Train Loss: 0.3020\tAvg Val Loss: 0.3307\t Train RMSE: 0.5496\t Val RMSE: 0.5750\n",
            "Epoch: 14/30\tAvg Train Loss: 0.3251\tAvg Val Loss: 0.3463\t Train RMSE: 0.5702\t Val RMSE: 0.5885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-393edbe267ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-75e58ea44a88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mscore_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/iwt-wot/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoded_sentence1, encoded_sentence2)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_sentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_sentence2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_hn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_hn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sentence2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ3TWs5H41je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLv9_m-lCDn",
        "colab_type": "text"
      },
      "source": [
        "## Testing for sub-task 1\n",
        "\n",
        "Below is our code for running models on the sub-task 1 test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd8thDcbo8XA",
        "colab_type": "text"
      },
      "source": [
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R3W1AbG3lGxc",
        "colab": {}
      },
      "source": [
        "from model import Model25 as Model1\n",
        "from preprocessing import model1preprocessing, task2preprocessing, TASK_1, EXTRA_TRAIN_TASK_1, TASK_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4544ea57-ca5c-4511-ae44-8f4452f21cad",
        "id": "IsQijgVjlGxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model1preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1, DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded training data')\n",
        "test_data = model1preprocessing([DRIVE_DIR / TASK_1 / 'test.csv'])\n",
        "print('loaded test data')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pU_fP2HllGxk",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for inputData, score in training_data[1::2]:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding)\n",
        "        \n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "    # avg_val_loss, val_rmse = evaluate(model, loss_function, optimizer)\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\t Train RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      train_rmse,\n",
        "                                                                      ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8f6fc794-289c-42e0-87cd-0697a28cac34",
        "id": "g5Ol1_p1lGxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "HIDDEN_DIM = 6\n",
        "LEARNING_RATE = 0.18\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 16\n",
        "\n",
        "print(device)\n",
        "model1 = Model1(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, model1, loss_function, optimizer)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/16\tAvg Train Loss: 0.3802\t Train RMSE: 0.6166\n",
            "Epoch: 2/16\tAvg Train Loss: 0.3718\t Train RMSE: 0.6098\n",
            "Epoch: 3/16\tAvg Train Loss: 0.3587\t Train RMSE: 0.5989\n",
            "Epoch: 4/16\tAvg Train Loss: 0.3468\t Train RMSE: 0.5889\n",
            "Epoch: 5/16\tAvg Train Loss: 0.3389\t Train RMSE: 0.5821\n",
            "Epoch: 6/16\tAvg Train Loss: 0.3332\t Train RMSE: 0.5773\n",
            "Epoch: 7/16\tAvg Train Loss: 0.3288\t Train RMSE: 0.5734\n",
            "Epoch: 8/16\tAvg Train Loss: 0.3249\t Train RMSE: 0.5700\n",
            "Epoch: 9/16\tAvg Train Loss: 0.3216\t Train RMSE: 0.5671\n",
            "Epoch: 10/16\tAvg Train Loss: 0.3185\t Train RMSE: 0.5643\n",
            "Epoch: 11/16\tAvg Train Loss: 0.3152\t Train RMSE: 0.5615\n",
            "Epoch: 12/16\tAvg Train Loss: 0.3124\t Train RMSE: 0.5589\n",
            "Epoch: 13/16\tAvg Train Loss: 0.3097\t Train RMSE: 0.5565\n",
            "Epoch: 14/16\tAvg Train Loss: 0.3067\t Train RMSE: 0.5538\n",
            "Epoch: 15/16\tAvg Train Loss: 0.3039\t Train RMSE: 0.5513\n",
            "Epoch: 16/16\tAvg Train Loss: 0.3011\t Train RMSE: 0.5487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ImTc-IztlGxm",
        "colab": {}
      },
      "source": [
        "def test_task1(model, loss_function, printErrors=False):\n",
        "    test_loss = 0\n",
        "    square_error = 0\n",
        "    test_examples = 0\n",
        "    errors = []\n",
        "    guesses = []\n",
        "    with torch.no_grad():\n",
        "        for inputData, score in test_data[1::2]:\n",
        "            embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "            score_output = model(embedding)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            errors.append(abs(score_output.item() - score))\n",
        "            guesses.append(score_output.item())\n",
        "\n",
        "            test_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / test_examples)\n",
        "    avg_test_loss = test_loss / test_examples\n",
        "\n",
        "    if printErrors:\n",
        "      error_indices_sorted = sorted(range(len(errors)), key=lambda index: -errors[index])\n",
        "      for i in range(10):\n",
        "        index = error_indices_sorted[i]\n",
        "        print('Number ' + str(i))\n",
        "        print(errors[index])\n",
        "        print(test_data[2*index][0])\n",
        "        sentence, score = test_data[2 * index + 1]\n",
        "        print(sentence)\n",
        "        print(score)\n",
        "        print(guesses[index])\n",
        "        print()\n",
        "\n",
        "    return avg_test_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcvnGcxxhAu",
        "colab_type": "code",
        "outputId": "6e68fb43-8f6b-454c-9e73-9dec451a7bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_task1(model1, loss_function)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.32591401598185044, 0.5708887965698799)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zrzMC56F6aT",
        "colab_type": "text"
      },
      "source": [
        "### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fWAjJYF8GGfj",
        "colab": {}
      },
      "source": [
        "from model import Model25 as Model2\n",
        "from preprocessing import model2preprocessing, TASK_1, EXTRA_TRAIN_TASK_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "789378ec-53bb-479c-c980-a0249e6da754",
        "id": "2wArOw8WGGfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model2preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1, DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded training data')\n",
        "test_data = model2preprocessing([DRIVE_DIR / TASK_1 / 'test.csv'])\n",
        "print('loaded test data')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MNpuvjn4GGfy",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for inputData, score in training_data:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding)\n",
        "\n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tTrain RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      train_rmse\n",
        "                                                                      ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d8f4cad6-b0e0-499c-dd45-6347be4746e7",
        "id": "jsctHgMGGGf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "HIDDEN_DIM = 6\n",
        "LEARNING_RATE = 0.2\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 14\n",
        "\n",
        "print(device)\n",
        "model2 = Model2(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "t_rmses = []\n",
        "v_rmses = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, model2, loss_function, optimizer)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/14\tAvg Train Loss: 0.3885\tTrain RMSE: 0.6233\n",
            "Epoch: 2/14\tAvg Train Loss: 0.3816\tTrain RMSE: 0.6177\n",
            "Epoch: 3/14\tAvg Train Loss: 0.3744\tTrain RMSE: 0.6119\n",
            "Epoch: 4/14\tAvg Train Loss: 0.3625\tTrain RMSE: 0.6020\n",
            "Epoch: 5/14\tAvg Train Loss: 0.3515\tTrain RMSE: 0.5928\n",
            "Epoch: 6/14\tAvg Train Loss: 0.3432\tTrain RMSE: 0.5858\n",
            "Epoch: 7/14\tAvg Train Loss: 0.3370\tTrain RMSE: 0.5805\n",
            "Epoch: 8/14\tAvg Train Loss: 0.3319\tTrain RMSE: 0.5761\n",
            "Epoch: 9/14\tAvg Train Loss: 0.3273\tTrain RMSE: 0.5721\n",
            "Epoch: 10/14\tAvg Train Loss: 0.3235\tTrain RMSE: 0.5688\n",
            "Epoch: 11/14\tAvg Train Loss: 0.3197\tTrain RMSE: 0.5654\n",
            "Epoch: 12/14\tAvg Train Loss: 0.3158\tTrain RMSE: 0.5620\n",
            "Epoch: 13/14\tAvg Train Loss: 0.3120\tTrain RMSE: 0.5585\n",
            "Epoch: 14/14\tAvg Train Loss: 0.3085\tTrain RMSE: 0.5554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xUox19noGGf3",
        "colab": {}
      },
      "source": [
        "def test_task1(model, loss_function):\n",
        "    test_loss = 0\n",
        "    square_error = 0\n",
        "    test_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputData, score in test_data:\n",
        "            embedding = torch.tensor(embed.embed_sentence(inputData)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        " \n",
        "            score_output = model(embedding)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            test_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / test_examples)\n",
        "    avg_test_loss = test_loss / test_examples\n",
        "    return avg_test_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whSuuo8gMSKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dcaae8a-20bc-4ff5-a15e-f1d2cfa6d2f2"
      },
      "source": [
        "test_task1(model2, loss_function)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3204903787416706, 0.5661186969624548)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SauO66QpIaJK",
        "colab_type": "text"
      },
      "source": [
        "### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhIL1snmIkSK",
        "colab": {}
      },
      "source": [
        "from model import Model3\n",
        "from preprocessing import model3preprocessing, TASK_1, EXTRA_TRAIN_TASK_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "181e6ed4-8924-4a79-e766-1116f8db0cd8",
        "id": "VjlA5MCwIkST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('about to load data')\n",
        "training_data = model3preprocessing([DRIVE_DIR / TASK_1 / 'train.csv', DRIVE_DIR / EXTRA_TRAIN_TASK_1, DRIVE_DIR / TASK_1 / 'dev.csv'])\n",
        "print('loaded training data')\n",
        "test_data = model3preprocessing([DRIVE_DIR / TASK_1 / 'test.csv'])\n",
        "print('loaded test data')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded training data\n",
            "loaded test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "udfUIjzPIkSa",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, loss_function, optimizer):\n",
        "    train_loss = 0\n",
        "    train_examples = 0\n",
        "    square_error = 0\n",
        "\n",
        "    for originalSent, newSent, score in training_data:\n",
        "        model.zero_grad()\n",
        "\n",
        "        embedding1 = torch.tensor(embed.embed_sentence(originalSent)).to(device)\n",
        "        embedding2 = torch.tensor(embed.embed_sentence(newSent)).to(device)\n",
        "        score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "        score_output = model(embedding1, embedding2)\n",
        "        \n",
        "        loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        square_error += (score_output.item() - score)**2\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_examples += 1\n",
        "\n",
        "    train_rmse = math.sqrt(square_error / train_examples)\n",
        "    avg_train_loss = train_loss / train_examples\n",
        "\n",
        "    print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\t Train RMSE: {:.4f}\".format(epoch,\n",
        "                                                                      EPOCHS,\n",
        "                                                                      avg_train_loss,\n",
        "                                                                      train_rmse\n",
        "                                                                      ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "599d4045-3654-4549-ae42-efa6e70ac70d",
        "id": "hNzQwUGYIkSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "HIDDEN_DIM = 3\n",
        "LEARNING_RATE = 0.18\n",
        "LSTM_LAYERS = 1\n",
        "DROPOUT = 0\n",
        "EPOCHS = 12\n",
        "\n",
        "print(device)\n",
        "model3 = Model3(HIDDEN_DIM, LSTM_LAYERS, DROPOUT).to(device)\n",
        "print(f'model loaded to device')\n",
        "optimizer = torch.optim.SGD(model3.parameters(), lr=LEARNING_RATE)\n",
        "# loss_function = nn.KLDivLoss(reduction='batchmean')\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, model3, loss_function, optimizer)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model loaded to device\n",
            "Epoch: 1/12\tAvg Train Loss: 0.3815\t Train RMSE: 0.6177\n",
            "Epoch: 2/12\tAvg Train Loss: 0.3727\t Train RMSE: 0.6105\n",
            "Epoch: 3/12\tAvg Train Loss: 0.3550\t Train RMSE: 0.5958\n",
            "Epoch: 4/12\tAvg Train Loss: 0.3434\t Train RMSE: 0.5860\n",
            "Epoch: 5/12\tAvg Train Loss: 0.3376\t Train RMSE: 0.5811\n",
            "Epoch: 6/12\tAvg Train Loss: 0.3335\t Train RMSE: 0.5775\n",
            "Epoch: 7/12\tAvg Train Loss: 0.3300\t Train RMSE: 0.5744\n",
            "Epoch: 8/12\tAvg Train Loss: 0.3267\t Train RMSE: 0.5715\n",
            "Epoch: 9/12\tAvg Train Loss: 0.3233\t Train RMSE: 0.5686\n",
            "Epoch: 10/12\tAvg Train Loss: 0.3200\t Train RMSE: 0.5657\n",
            "Epoch: 11/12\tAvg Train Loss: 0.3171\t Train RMSE: 0.5631\n",
            "Epoch: 12/12\tAvg Train Loss: 0.3143\t Train RMSE: 0.5606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6NJFsYvOIkSf",
        "colab": {}
      },
      "source": [
        "def test_task1(model, loss_function):\n",
        "    test_loss = 0\n",
        "    square_error = 0\n",
        "    test_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for originalSent, newSent, score in test_data:\n",
        "            embedding1 = torch.tensor(embed.embed_sentence(originalSent)).to(device)\n",
        "            embedding2 = torch.tensor(embed.embed_sentence(newSent)).to(device)\n",
        "            score_tensor = torch.tensor([score]).to(device)\n",
        "\n",
        "            score_output = model(embedding1, embedding2)\n",
        "\n",
        "            loss = loss_function(score_output.view((1, -1)), score_tensor.view((1, -1)))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            square_error += (score_output.item() - score)**2\n",
        "\n",
        "            test_examples += 1\n",
        "\n",
        "    rmse = math.sqrt(square_error / test_examples)\n",
        "    avg_test_loss = test_loss / test_examples\n",
        "    return avg_test_loss, rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhqYDvr_eS83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b837457d-8f7b-4a1f-d6ae-2a1747f947f7"
      },
      "source": [
        "test_task1(model3, loss_function)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35087820722193647, 0.5923497363270405)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO3FoSJbe-uo",
        "colab_type": "text"
      },
      "source": [
        "# Sub-task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlutUbbNfASF",
        "colab_type": "text"
      },
      "source": [
        "## Training for sub-task 2\n",
        "\n",
        "We simply use the validation data for sub-task 2 to train the MARGIN parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFG53k1pxiG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_task2(model, margin, printErrors=False):\n",
        "    test_correct = 0\n",
        "    test_examples = 0\n",
        "    scores1 = []\n",
        "    scores2 = []\n",
        "    predictions = []\n",
        "    confidences = []\n",
        "    with torch.no_grad():\n",
        "        for (_, input1, _, input2, label) in test_data_task2:\n",
        "            embedding1 = torch.tensor(embed.embed_sentence(input1)).to(device)\n",
        "            embedding2 = torch.tensor(embed.embed_sentence(input2)).to(device)\n",
        "\n",
        "            score_output1 = model(embedding1)\n",
        "            score_output2 = model(embedding2)\n",
        "\n",
        "            winner = 0\n",
        "            if score_output1.item() > score_output2.item() + margin:\n",
        "              winner = 1\n",
        "            elif score_output1.item() < score_output2.item() - margin:\n",
        "              winner = 2\n",
        "\n",
        "            scores1.append(score_output1.item())\n",
        "            scores2.append(score_output2.item())\n",
        "            confidences.append(abs(score_output1.item() - score_output2.item()))\n",
        "            predictions.append(winner)\n",
        "\n",
        "            if winner == label:\n",
        "              test_correct += 1\n",
        "\n",
        "            test_examples += 1\n",
        "\n",
        "    if printErrors:\n",
        "      confidence_indices_sorted = sorted(range(len(confidences)), key=lambda index: -confidences[index])\n",
        "      for i in range(10):\n",
        "        index = confidence_indices_sorted[i]\n",
        "        print('Number ' + str(i))\n",
        "        print(confidences[index])\n",
        "        (_, input1, _, input2, label) = test_data_task2[index]\n",
        "        print(input1)\n",
        "        print(scores1[index])\n",
        "        print(input2)\n",
        "        print(scores2[index])\n",
        "        print(predictions[index])\n",
        "        print(label)\n",
        "        print()\n",
        "\n",
        "    acc = test_correct / test_examples\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbtMlF6HMVR6",
        "colab_type": "code",
        "outputId": "3d07715c-3e20-40c4-f3b1-79cfaa7e14ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('about to load data')\n",
        "test_data_task2 = task2preprocessing([DRIVE_DIR / TASK_2 / 'dev.csv'])\n",
        "print('loaded test data')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtGJabnvOY-d",
        "colab_type": "code",
        "outputId": "83b321b3-be37-4cd6-fbc2-f73d1e158e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MARGIN = 0.0004\n",
        "test_task2(model1, MARGIN)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5749469214437367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPoL0VZG4QNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "accs = []\n",
        "margins = np.arange(0, 0.002, 0.0001)\n",
        "\n",
        "for marg in margins:\n",
        "  accs.append(test_task2(model1, marg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM4e6nN244F_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6bac042d-ff8a-4de4-84c4-ce6d9d378c4d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(margins, accs)\n",
        "plt.xlabel('margin')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.savefig('margins.png')\n",
        "plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2ZO7s1CfPG0",
        "colab_type": "text"
      },
      "source": [
        "## Testing for sub-task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK6Zi_OiOnJm",
        "colab_type": "code",
        "outputId": "c91634df-a3dd-4f8f-8209-a5432b1db54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('about to load data')\n",
        "test_data_task2 = task2preprocessing([DRIVE_DIR / TASK_2 / 'test.csv'])\n",
        "print('loaded test data')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about to load data\n",
            "loaded test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjxVzNHOfWbV",
        "colab_type": "code",
        "outputId": "2f920ea1-3267-4ae8-ba6a-87ea938b587e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MARGIN = 0.0004\n",
        "test_task2(model1, MARGIN)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5472972972972973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6XdvZUQfXmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}